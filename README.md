## ğŸ“˜ Notebook: 01_get_dados.py 01_get_dados.py 
Tem objetivo em fazer a coleta de dados utilizando a API do Kaggle, baixando o dataset de detecÃ§Ã£o de fraudes em cartÃ£o de crÃ©dito e carregÃ¡-lo em um Dataframe Spark e persisti-lo em uma tabela delta para consumo futuro.
---
<details>
  <summary><strong>ğŸ“– Clique para expandir a explicaÃ§Ã£o do notebook</strong></summary>
  
### ğŸ”§ 1. InstalaÃ§Ã£o de Pacotes
Instala bibliotecas essenciais para manipulaÃ§Ã£o de dados, visualizaÃ§Ã£o, balanceamento de classes e machine learning com PySpark:

```bash
pip install pandas matplotlib imbalanced-learn pyspark
```

---

### ğŸ“¦ 2. ImportaÃ§Ã£o de Bibliotecas

Importa mÃ³dulos como:

- `pandas`, `matplotlib.pyplot` â€” manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados.
- `SMOTE` â€” balanceamento de classes.
- `pyspark.ml` â€” criaÃ§Ã£o de pipelines de machine learning.

---

### ğŸ” 3. ConfiguraÃ§Ã£o da API do Kaggle

Cria e copia o arquivo `kaggle.json` com as credenciais de acesso Ã  API do Kaggle para autenticaÃ§Ã£o segura.

---

### ğŸ”‘ 4. AutenticaÃ§Ã£o com a API do Kaggle

Autentica o usuÃ¡rio com a API do Kaggle usando a biblioteca `KaggleApi`.

---

### ğŸ“¥ 5. Download do Dataset

Baixa o dataset `mlg-ulb/creditcardfraud` diretamente do Kaggle e salva localmente no diretÃ³rio `/dbfs/FileStore/creditcard`.

---

### ğŸ“‚ 6. Leitura dos Dados com Spark

Carrega o arquivo CSV para um DataFrame do Spark com detecÃ§Ã£o automÃ¡tica de tipos de dados:

```python
df = spark.read.csv("file:/dbfs/FileStore/creditcard/creditcard.csv", header=True, inferSchema=True)
```

---

### ğŸ’¾ 7. PersistÃªncia em Tabela Delta

Salva o DataFrame como uma tabela Delta chamada `credit_card_fraud`, permitindo consultas SQL otimizadas:

```python
df.write.format("delta").mode("overwrite").saveAsTable("credit_card_fraud")
```

---

### ğŸ” 8. Consulta SQL

Exibe as primeiras linhas da tabela criada:

```sql
SELECT * FROM credit_card_fraud LIMIT 5
```

---
</details>
